1.交叉验证 (Cross-Validation):
    交叉验证是一种用于评估机器学习模型性能和可靠性的统计方法。
    它的核心思想是将原始数据集反复地分割成训练集（Training Set）和测试集（Testing Set），然后用训练集来训练模型，用测试集来评估模型。
k折交叉验证（k-Fold Cross-Validation）:
    确定k值：将一个常数k（通常是5或10）作为折数（Folds）。
    分割数据集：将原始数据集随机打乱并平均分成k个大小相似的互斥子集，称为“折”（Fold）。
    进行k次循环：
    在每一次循环中，将1个折作为测试集，剩下的 k-1个折合并起来作为训练集。
    用训练集训练模型。
    用测试集评估模型，得到一个性能评分（如准确率、精确率等）。
    汇总结果：k次循环结束后，你会得到k个模型性能评分。最终模型的性能评估结果是这k个评分的平均值。
    这个过程确保了每个子集都有且仅有一次被用作测试集。



2.混淆矩阵（Confusion Matrix）：
    混淆矩阵是一个特定的表格布局，用于可视化一个分类模型的性能。
    它将模型的预测结果与数据的真实标签进行对比，并汇总成四个核心类别，从而让我们能够清楚地看到模型在哪些地方做对了，在哪些地方混淆了
                         真实值为 Positive (1)         真实值为 Negative (0)
预测为 Positive (1)    TP (True Positive，真正例)    FP (False Positive，假正例)
预测为 Negative (0)    FN (False Negative，假负例)   TN (True Negative，真负例)

准确率 (Accuracy)：
    所有预测中，猜对的比例
    (TP + TN) / (TP + TN + FP + FN)
精确率 (Precision)：
    在所有预测为“正”的案例中，有多少是预测正确的。衡量的是模型的“准不准”：
    TP / (TP + FP)
召回率 (Recall)，又称敏感性(Sensitivity)：
    在所有真实为“正”的案例中，模型成功预测出了多少。衡量的是模型的“全不全”，有没有漏掉：
    TP / (TP + FN)
特异性（Specificity）：
    在所有真实为“负”的案例中，模型成功预测出了多少。
    TN / (TN + FP)
如果你想评估模型找出所有特定类别（如“苹果”）的能力，就看该类的敏感性。
如果你想评估模型避免将其他东西误认为特定类别的能力，就看该类的特异性。



3.偏差 (Bias)：
    定义：偏差衡量了模型的平均预测结果与真实值之间的差距。即模型本身的拟合能力有多强。
    高偏差：模型过于简单，无法捕捉数据中的潜在规律（欠拟合）。无论给多少数据，它的平均预测都和真实值差得很远。
    低偏差：模型复杂度足够，平均预测结果很接近真实值。

方差 (Variance)：
    定义：方差衡量了模型对于不同训练数据集的敏感程度。即模型的稳定性有多高。
    高方差：模型过于复杂，完美地学习了训练数据中的每一个细节，包括噪声。导致换一份数据训练，模型的表现差异就非常大（过拟合）。
    低方差：模型很简单，换不同的数据训练，模型的变化不大，表现很稳定。



4.熵 (Entropy)：
    衡量一个系统的不确定性、混乱程度或者惊喜度。不确定性越高，熵越大。确定性越高，熵越小。
    计算方式见：书签（熵的计算）



5.决定系数(R-squared)：
    用于衡量回归模型（如线性回归）的拟合优度（Goodness of Fit）。
    R² = ESS / TSS = 1 - (SSE / SST)
    模型的功劳 / 总的问题的规模。这个比值越大，说明模型的功劳占比越大，模型就越好。|从“误差剩余”的角度出发。
    一个回归模型所解释的因变量（目标变量）的方差占其总方差的比例。
    它的值域在 0 到 1 之间（有时也会用百分比 0% 到 100% 表示）。
    R² = 0：意味着你的模型完全无法解释因变量的任何波动。模型是无效的。
    R² = 1：意味着你的模型完美地解释了因变量的所有波动。所有数据点都恰好落在回归线上。
    通常，R² 的值介于两者之间，值越高，表明模型的自变量对因变量的解释能力越强，模型的拟合效果越好。

yᵢ是每个数据点的实际值。
ȳ 是所有实际值的平均值。
ŷᵢ是模型对每个数据点的预测值。

SST (Total Sum of Squares) - 总平方和
    SST = Σ(yᵢ - ȳ)²
    SST 衡量的是数据点围绕均值分布的分散程度。

SSR (Regression Sum of Squares) - 回归平方和
    SSR = Σ(ŷᵢ - ȳ)²
    表示由于模型的影响而带来的波动。它衡量的是预测值围绕均值的分散程度。这个分散是由回归线（模型）造成的，所以是模型解释掉的部分。

SSE (Error Sum of Squares) - 残差平方和（又名RSS(Residual Sum of Squares)）
    SSE = Σ(yᵢ - ŷᵢ)²
    表示模型无法解释的波动，即误差。它衡量的是数据点距离回归线的远近。距离越远，误差越大。

只要你向模型中增加新的自变量，无论这个变量是否与因变量真正相关，R-squared 的值都会保持不变或增加（几乎总是增加）。
即使加入一个随机变量，模型也总能“抓到”一点数据中的随机噪声，从而稍微减少一点SSE（误差）
根据公式 R² = 1 - (SSE / SST)，SST不变，SSE减小，R² 就会增大。
总波动 (TSS) = 模型解释掉的波动 (ESS) + 模型无法解释的波动 (RSS)
Σ(yᵢ - ȳ)² = Σ(ŷᵢ - ȳ)² + Σ(yᵢ - ŷᵢ)²
一个理想的模型，其目标就是最大化自己的功劳 (ESS)，同时最小化自己的失误 (RSS)。



6.联合概率 (joint probability)：
    联合概率指的是多个事件同时发生的概率。它衡量的是两个或更多事件交集的可能性。
    P(A, B) 或 P(A ∩ B) = 事件 A 和 事件 B 同时发生的概率。
边际概率(marginal probability)：
    边际概率是在联合概率分布中，只关心某一个事件的发生概率，而忽略其他事件的所有可能情况
    P(A) = 事件 A 发生的概率（无论 B 发生与否）
         = 所有包含 A 的联合概率之和
         = P(A, B₁) + P(A, B₂) + P(A, B₃) + ... (对所有可能的 B 求和)


7.互信息 (Mutual Information, MI)：
    互信息是信息论中的一个核心概念，用于衡量两个随机变量之间的相互依赖程度。
    更具体地说，它回答的问题是：“我知道一个变量X的信息后，能减少另一个变量Y的不确定性多少？”
I(X; Y) = Σₓ Σᵧ P(x, y) * log( P(x, y) / (P(x)P(y)) )
    计算方式见：书签（互信息的计算）
    核心比值：P(x, y) / (P(x)P(y))
    这个比值揭示了X和Y的真实关系与独立假设之间的偏离程度：
    如果比值 = 1：
    P(x, y) = P(x)P(y)
    这意味着对于这对具体的 (x, y)，X和Y是独立的。知道x的发生，对你猜测y的发生没有任何帮助，反之亦然。它们之间没有共享信息。
    如果比值 > 1：
    P(x, y) > P(x)P(y)
    这意味着x和y同时出现的概率比随机巧合要高得多。它们倾向于一起发生。知道x发生了，会极大地提高你预测y也会发生的信心。
    如果比值 < 1：
    P(x, y) < P(x)P(y)
    这意味着x和y同时出现的概率比随机巧合要低。它们倾向于互斥。知道x发生了，会极大地降低你预测y也会发生的信心。


8.简单线性回归(Simple Linear Regression)；
    是一种用于研究自变量（independent variable）与因变量（dependent variable）之间线性关系的统计方法，其核心是通过建立线性数学模型，
    来描述自变量的变化如何影响因变量的变化，并基于样本数据估计模型参数，最终用于预测或解释变量间的关系。
普通最小二乘法(Ordinary Least Squares,OLS)：
    找到一条直线，使得所有数据点到这条直线的垂直距离（称为“残差”或“误差”）的平方和最小
    即使RSS = Σ(yᵢ - ŷᵢ)²最小
均方（MS）= 平方和（Sum of Squares，简称SS）/自由度（Degrees of Freedom，简称df）
    平方和（SS）：反映数据与某个参考值（如均值）之间的总偏差平方和，衡量了数据的总变异程度。
    自由度（df）：反映计算平方和时独立数据点的数量（或自由变化的参数数量），用于校正平方和的偏差。

F 统计量：
    F统计量是用于检验整个回归模型整体显著性的指标。
    公式见：书签(F统计量公式)
    F=MSR/MSE
     =(SSR/df_R)/(SSE/df_E)
     =(模型解释的方差/自由度)/(残差方差/自由度)
     =(SSR/p)/(SSE/(n-p-1))

理解一：
MSR (Mean Square Due to Regression | 回归均方):
    SSR (Sum of Squares Due to Regression | 回归平方和):
        SSR = Σ(ŷᵢ - ȳ)²
    df_R (Regression Degrees of Freedom | 回归自由度)：等于模型中自变量的个数，通常记为 p。
        例如，模型 y = β₀ + β₁x₁ + β₂x₂ 中有2个自变量，所以 p = 2，df_R = 2。
MSR = SSR / df_R：代表了每个自变量平均能解释的变异。

MSE (Mean Square Due to Error | 残差均方):
    SSE (Sum of Squares Due to Error | 残差平方和)：
        SSE = Σ(yᵢ - ŷᵢ)²
    df_E (Error Degrees of Freedom | 残差自由度)：等于样本量减去模型等待估计的参数（模型参数总个数）。
        模型参数总个数 = 自变量个数 (p) + 1（截距项β₀）。
        df_E = n - p - 1，其中 n 是样本量。
MSE = SSE / df_E：代表了排除模型影响后，数据中剩余的、未被解释的平均变异。

分子：我的模型有多好？模型能解释多少变异（组间差异、解释平方和）。
分母：我的模型有多差？模型没解释掉的变异（组内差异、残差平方和）。
如果模型真的有用，那么分子会显著大于分母 ⇒ F 值大。
如果模型没用，那么分子 ≈ 分母 ⇒ F 值接近 1。

理解二：
SS_mean：使用“平均值模型”时的残差平方和。Σ(yᵢ - ȳ)²        SST（总平方和）
“平均值模型”就是最简单的模型：y = β₀ + ε。它只有一个参数（β₀，即均值），所以其参数数量 p_mean = 1。
这个模型的预测值对于所有数据点都是同一个值 ȳ（平均值）。
这个值衡量了数据本身的总波动性。

SS_fit：使用“拟合模型”后的残差平方和。Σ(yᵢ - ŷᵢ)²          SSE（残差平方和）
“拟合模型”就是你的回归方程，例如一条直线 y = β₀ + β₁x + ε。它有两个参数（β₀ 和 β₁），所以其参数数量 p_fit = 2。
这个模型的预测值 ŷ 是因变量在自变量条件下的条件均值。
这个值衡量了拟合模型后仍然无法解释的剩余波动。

F统计量衡量的是：从“平均值模型”到“拟合模型”，每个新增参数所能解释的波动比例的提升，相对于模型剩余的平均无法解释的波动，有多大。
a.模型改善了多少？
从只用均值(p=1)到使用拟合模型(p=2)，平方和减少了 (SS_mean - SS_fit)。
这减少的部分，就是回归模型所解释的波动，即 SSR：SSR = SS_mean - SS_fit。
b.为这个改善付出了多少代价？
代价是我们引入了更多的参数。新增参数的数量是 (p_fit - p_mean) = 2 - 1 = 1。
所以，每个新增参数平均带来的改善是：(SST - SSE) / (p_fit - p_mean)
c.改善的“性价比”高吗？
我们需要一个基准来衡量这个改善是否显著。这个基准就是拟合后每个数据点平均承担的无法解释的波动，即 SS_fit / (n - p_fit)。
这里的 (n - p_fit) 是残差的自由度（样本量减去拟合模型的参数总数）。
最终，F统计量就是这个“性价比”的比值：
F = 每个新增参数带来的平均改善/剩余的平均无法解释的波动

原假设 (H₀)：β₁ = β₂ = ... = βₙ = 0 （所有自变量对预测因变量都没有任何作用）
备择假设 (H₁)：至少有一个βᵢ ≠ 0 （至少有一个自变量对预测因变量是有用的）
F统计量服从F分布，这个分布由两个自由度参数决定（分子自由度和分母自由度）。
在原假设H₀为真的前提下，

P值（P-Value） 是在假设原假设（Null Hypothesis, H₀）为真时（无关），观察到当前样本数据（或更极端数据）的概率。
比如：
H₀：各组均值相等 / 回归模型系数全为 0。
计算出一个 F 值，查对应的 F 分布，得到在 H₀ 成立下得到 ≥ 该 F 值的概率。
这个概率就是 p-value。
F统计量是“检验强度”的度量（值越大，越可能拒绝零假设）。
p-value 是“拒绝零假设的证据大小”（概率越小，越有理由拒绝）。
举例：
对于一个双因素ANOVA（方差分析Analysis of Variance），得到 F = 5.2，自由度为 (3, 40)。
查 F 分布表，或者用 Python scipy.stats.f.sf(5.2, 3, 40)计算。
得到 p ≈ 0.004。
说明：在零假设为真时，得到一个 F ≥ 5.2 的概率只有 0.4%，很小 → 拒绝零假设。即有关。
























