1.交叉验证 (Cross-Validation):
    交叉验证是一种用于评估机器学习模型性能和可靠性的统计方法。
    它的核心思想是将原始数据集反复地分割成训练集（Training Set）和测试集（Testing Set），然后用训练集来训练模型，用测试集来评估模型。
k折交叉验证（k-Fold Cross-Validation）:
    确定k值：将一个常数k（通常是5或10）作为折数（Folds）。
    分割数据集：将原始数据集随机打乱并平均分成k个大小相似的互斥子集，称为“折”（Fold）。
    进行k次循环：
    在每一次循环中，将1个折作为测试集，剩下的 k-1个折合并起来作为训练集。
    用训练集训练模型。
    用测试集评估模型，得到一个性能评分（如准确率、精确率等）。
    汇总结果：k次循环结束后，你会得到k个模型性能评分。最终模型的性能评估结果是这k个评分的平均值。
    这个过程确保了每个子集都有且仅有一次被用作测试集。



2.混淆矩阵（Confusion Matrix）：
    混淆矩阵是一个特定的表格布局，用于可视化一个分类模型的性能。
    它将模型的预测结果与数据的真实标签进行对比，并汇总成四个核心类别，从而让我们能够清楚地看到模型在哪些地方做对了，在哪些地方混淆了
                         真实值为 Positive (1)         真实值为 Negative (0)
预测为 Positive (1)    TP (True Positive，真正例)    FP (False Positive，假正例)
预测为 Negative (0)    FN (False Negative，假负例)   TN (True Negative，真负例)

准确率 (Accuracy)：
    所有预测中，猜对的比例
    (TP + TN) / (TP + TN + FP + FN)
精确率 (Precision)：
    在所有预测为“正”的案例中，有多少是预测正确的。衡量的是模型的“准不准”：
    TP / (TP + FP)
召回率 (Recall)，又称敏感性(Sensitivity)：
    在所有真实为“正”的案例中，模型成功预测出了多少。衡量的是模型的“全不全”，有没有漏掉：
    TP / (TP + FN)
特异性（Specificity）：
    在所有真实为“负”的案例中，模型成功预测出了多少。
    TN / (TN + FP)
如果你想评估模型找出所有特定类别（如“苹果”）的能力，就看该类的敏感性。
如果你想评估模型避免将其他东西误认为特定类别的能力，就看该类的特异性。



3.偏差 (Bias)：
    定义：偏差衡量了模型的平均预测结果与真实值之间的差距。即模型本身的拟合能力有多强。
    高偏差：模型过于简单，无法捕捉数据中的潜在规律（欠拟合）。无论给多少数据，它的平均预测都和真实值差得很远。
    低偏差：模型复杂度足够，平均预测结果很接近真实值。

方差 (Variance)：
    定义：方差衡量了模型对于不同训练数据集的敏感程度。即模型的稳定性有多高。
    高方差：模型过于复杂，完美地学习了训练数据中的每一个细节，包括噪声。导致换一份数据训练，模型的表现差异就非常大（过拟合）。
    低方差：模型很简单，换不同的数据训练，模型的变化不大，表现很稳定。



4.熵 (Entropy)：
    衡量一个系统的不确定性、混乱程度或者惊喜度。不确定性越高，熵越大。确定性越高，熵越小。
    计算方式见：书签（熵的计算）



5.决定系数(R-squared)：
    用于衡量回归模型（如线性回归）的拟合优度（Goodness of Fit）。
    R² = ESS / TSS = 1 - (SSE / SST)
    模型的功劳 / 总的问题的规模。这个比值越大，说明模型的功劳占比越大，模型就越好。|从“误差剩余”的角度出发。
    一个回归模型所解释的因变量（目标变量）的方差占其总方差的比例。
    它的值域在 0 到 1 之间（有时也会用百分比 0% 到 100% 表示）。
    R² = 0：意味着你的模型完全无法解释因变量的任何波动。模型是无效的。
    R² = 1：意味着你的模型完美地解释了因变量的所有波动。所有数据点都恰好落在回归线上。
    通常，R² 的值介于两者之间，值越高，表明模型的自变量对因变量的解释能力越强，模型的拟合效果越好。

yᵢ是每个数据点的实际值。
ȳ 是所有实际值的平均值。
ŷᵢ是模型对每个数据点的预测值。

SST (Total Sum of Squares) - 总平方和
    SST = Σ(yᵢ - ȳ)²
    SST 衡量的是数据点围绕均值分布的分散程度。

SSR (Regression Sum of Squares) - 回归平方和
    SSR = Σ(ŷᵢ - ȳ)²
    表示由于模型的影响而带来的波动。它衡量的是预测值围绕均值的分散程度。这个分散是由回归线（模型）造成的，所以是模型解释掉的部分。

SSE (Error Sum of Squares) - 残差平方和（又名RSS(Residual Sum of Squares)）
    SSE = Σ(yᵢ - ŷᵢ)²
    表示模型无法解释的波动，即误差。它衡量的是数据点距离回归线的远近。距离越远，误差越大。

只要你向模型中增加新的自变量，无论这个变量是否与因变量真正相关，R-squared 的值都会保持不变或增加（几乎总是增加）。
即使加入一个随机变量，模型也总能“抓到”一点数据中的随机噪声，从而稍微减少一点SSE（误差）
根据公式 R² = 1 - (SSE / SST)，SST不变，SSE减小，R² 就会增大。
总波动 (TSS) = 模型解释掉的波动 (ESS) + 模型无法解释的波动 (RSS)
Σ(yᵢ - ȳ)² = Σ(ŷᵢ - ȳ)² + Σ(yᵢ - ŷᵢ)²
一个理想的模型，其目标就是最大化自己的功劳 (ESS)，同时最小化自己的失误 (RSS)。



6.联合概率 (joint probability)：
    联合概率指的是多个事件同时发生的概率。它衡量的是两个或更多事件交集的可能性。
    P(A, B) 或 P(A ∩ B) = 事件 A 和 事件 B 同时发生的概率。
边际概率(marginal probability)：
    边际概率是在联合概率分布中，只关心某一个事件的发生概率，而忽略其他事件的所有可能情况
    P(A) = 事件 A 发生的概率（无论 B 发生与否）
         = 所有包含 A 的联合概率之和
         = P(A, B₁) + P(A, B₂) + P(A, B₃) + ... (对所有可能的 B 求和)


7.互信息 (Mutual Information, MI)：
    互信息是信息论中的一个核心概念，用于衡量两个随机变量之间的相互依赖程度。
    更具体地说，它回答的问题是：“我知道一个变量X的信息后，能减少另一个变量Y的不确定性多少？”
I(X; Y) = Σₓ Σᵧ P(x, y) * log( P(x, y) / (P(x)P(y)) )
    计算方式见：书签（互信息的计算）
    核心比值：P(x, y) / (P(x)P(y))
    这个比值揭示了X和Y的真实关系与独立假设之间的偏离程度：
    如果比值 = 1：
    P(x, y) = P(x)P(y)
    这意味着对于这对具体的 (x, y)，X和Y是独立的。知道x的发生，对你猜测y的发生没有任何帮助，反之亦然。它们之间没有共享信息。
    如果比值 > 1：
    P(x, y) > P(x)P(y)
    这意味着x和y同时出现的概率比随机巧合要高得多。它们倾向于一起发生。知道x发生了，会极大地提高你预测y也会发生的信心。
    如果比值 < 1：
    P(x, y) < P(x)P(y)
    这意味着x和y同时出现的概率比随机巧合要低。它们倾向于互斥。知道x发生了，会极大地降低你预测y也会发生的信心。


8.简单线性回归(Simple Linear Regression)；
    是一种用于研究自变量（independent variable）与因变量（dependent variable）之间线性关系的统计方法，其核心是通过建立线性数学模型，
    来描述自变量的变化如何影响因变量的变化，并基于样本数据估计模型参数，最终用于预测或解释变量间的关系。
普通最小二乘法(Ordinary Least Squares,OLS)：
    找到一条直线，使得所有数据点到这条直线的垂直距离（称为“残差”或“误差”）的平方和最小
    即使RSS = Σ(yᵢ - ŷᵢ)²最小


    P值（P-Value） 是在假设原假设（Null Hypothesis, H₀）为真时，观察到当前样本数据（或更极端数据）的概率。


























